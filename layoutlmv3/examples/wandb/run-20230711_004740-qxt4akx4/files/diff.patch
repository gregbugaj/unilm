diff --git a/layoutlmv3/README-GB.md b/layoutlmv3/README-GB.md
index bd4f519..b664f61 100644
--- a/layoutlmv3/README-GB.md
+++ b/layoutlmv3/README-GB.md
@@ -21,11 +21,17 @@ python -m torch.distributed.launch --nproc_per_node=1 ./train.py
 ``` 
 
 
-
 ```
 tensorboard --logdir=./logs
 ```
 
+```
+wandb server start --upgrade
+```
+
+```
+wandb login --relogin
+```
 
 
 LARGE
@@ -248,6 +254,72 @@ LARGE
 
 
 
+-- BASE 
+wandb: Run summary:
+wandb:                  eval/accuracy 0.89267
+wandb:                        eval/f1 0.84425
+wandb:                      eval/loss 1.22023
+wandb:                 eval/precision 0.83448
+wandb:                    eval/recall 0.85426
+wandb:                   eval/runtime 8.3803
+wandb:        eval/samples_per_second 47.134
+wandb:          eval/steps_per_second 47.134
+wandb:                    train/epoch 50.25
+wandb:              train/global_step 10000
+wandb:            train/learning_rate 0.0
+wandb:                     train/loss 0.0001
+wandb:               train/total_flos 1.0610876067072e+16
+wandb:               train/train_loss 0.04689
+wandb:            train/train_runtime 1368.8808
+wandb: train/train_samples_per_second 29.221
+wandb:   train/train_steps_per_second 7.305
+
+
+
+--- BASE SEGMENT_CURRENT_LINE
+
+wandb: 
+wandb: Run history:
+wandb:                  eval/accuracy ▅▄▁▄▇▆▆▅██▇
+wandb:                        eval/f1 ▄▅▁▄█▆▄▃▅▅█
+wandb:                      eval/loss ▁▄▅▆▇▅▆▇▇█▇
+wandb:                 eval/precision ▄▅▁▅█▆▃▁▄▅█
+wandb:                    eval/recall ▄▅▁▄█▇▆▅▆▆█
+wandb:                   eval/runtime ▆█▇▁▅▆▃▃▅▄▄
+wandb:        eval/samples_per_second ▂▁▂█▃▃▅▅▃▅▅
+wandb:          eval/steps_per_second ▂▁▂█▃▃▅▅▃▅▅
+wandb:                    train/epoch ▁▁▁▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▇▇▇▇▇█████
+wandb:              train/global_step ▁▁▁▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▆▆▆▇▇▇▇▇█████
+wandb:            train/learning_rate ██▇▇▇▆▆▅▅▅▄▄▄▃▃▂▂▂▁▁
+wandb:                     train/loss █▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
+wandb:               train/total_flos ▁
+wandb:               train/train_loss ▁
+wandb:            train/train_runtime ▁
+wandb: train/train_samples_per_second ▁
+wandb:   train/train_steps_per_second ▁
+wandb: 
+wandb: Run summary:
+wandb:                  eval/accuracy 0.9023
+wandb:                        eval/f1 0.86765
+wandb:                      eval/loss 1.1141
+wandb:                 eval/precision 0.85966
+wandb:                    eval/recall 0.87579
+wandb:                   eval/runtime 9.6308
+wandb:        eval/samples_per_second 41.014
+wandb:          eval/steps_per_second 41.014
+wandb:                    train/epoch 50.25
+wandb:              train/global_step 10000
+wandb:            train/learning_rate 0.0
+wandb:                     train/loss 0.0001
+wandb:               train/total_flos 1.0610876067072e+16
+wandb:               train/train_loss 0.0379
+wandb:            train/train_runtime 1663.565
+wandb: train/train_samples_per_second 24.045
+wandb:   train/train_steps_per_second 6.011
+
+
+
+
 # Reference 
 
 [Max_seq_length LayoutLMV3 - How to implement it ? #942](https://github.com/microsoft/unilm/issues/942)
diff --git a/layoutlmv3/examples/funsd_dataset/funsd_dataset.py b/layoutlmv3/examples/funsd_dataset/funsd_dataset.py
index 6b250a5..d896168 100644
--- a/layoutlmv3/examples/funsd_dataset/funsd_dataset.py
+++ b/layoutlmv3/examples/funsd_dataset/funsd_dataset.py
@@ -153,6 +153,8 @@ class Funsd(datasets.GeneratorBasedBuilder):
         downloaded_file = "/data/dataset/private/corr-indexer-augmented"
         # downloaded_file = "/home/greg/dataset/assets-private/corr-indexer-augmented"
         downloaded_file = "/home/gbugaj/datasets/private/corr-indexer-augmented"
+        downloaded_file = "/home/greg/datasets/private/assets-private/corr-indexer-augmented"
+        # downloaded_file = "/home/gbugaj/dataset/private/corr-indexer-augmented"
 
         return [
             datasets.SplitGenerator(
@@ -179,7 +181,6 @@ class Funsd(datasets.GeneratorBasedBuilder):
         ann_dir = os.path.join(self.filepath, "annotations")
         img_dir = os.path.join(self.filepath, "images")
 
-        print(guid)
         tokens = []
         bboxes = []
         ner_tags = []
@@ -220,7 +221,10 @@ class Funsd(datasets.GeneratorBasedBuilder):
                     tokens.append(w["text"])
                     ner_tags.append("I-" + label.upper())
                     cur_line_bboxes.append(normalize_bbox(w["box"], size))
-            # cur_line_bboxes = self.get_line_bbox(cur_line_bboxes)
+
+                # by default: --segment_level_layout 1
+                # if do not want to use segment_level_layout, comment the following line
+                cur_line_bboxes = self.get_line_bbox(cur_line_bboxes)
 
             if False:
                 boxed = True
diff --git a/layoutlmv3/examples/train.py b/layoutlmv3/examples/train.py
index c41ad25..11c5a7a 100644
--- a/layoutlmv3/examples/train.py
+++ b/layoutlmv3/examples/train.py
@@ -80,6 +80,7 @@ if False:
 # processor = AutoProcessor.from_pretrained("microsoft/layoutlmv3-base", apply_ocr=False)
 
 model_name_or_path = "microsoft/layoutlmv3-large"
+model_name_or_path = "microsoft/layoutlmv3-base"
 
 config = AutoConfig.from_pretrained (
     model_name_or_path,
@@ -87,9 +88,9 @@ config = AutoConfig.from_pretrained (
     finetuning_task="ner",
     cache_dir="/mnt/data/cache",
     input_size=224,
-    hidden_dropout_prob = .2,
-    attention_probs_dropout_prob = .2,
-    has_relative_attention_bias=False
+    # hidden_dropout_prob = .1,
+    # attention_probs_dropout_prob = .1,
+    # has_relative_attention_bias=False
 )
 
 # config.hidden_dropout_prob = 0.2
@@ -140,7 +141,14 @@ def prepare_examples(examples):
   boxes = examples[boxes_column_name]
   word_labels = examples[label_column_name]
 
-  encoding = processor(images, words, boxes=boxes, word_labels=word_labels, truncation=True,  padding="max_length")
+#   encoding = processor(images, words, boxes=boxes, word_labels=word_labels, truncation=True,  padding="max_length")
+
+  encoding = processor(images, words, boxes=boxes, word_labels=word_labels, truncation=True, stride =128, 
+         padding="max_length", max_length=512, return_overflowing_tokens=True, return_offsets_mapping=True)  
+  
+  offset_mapping = encoding.pop('offset_mapping')
+  overflow_to_sample_mapping = encoding.pop('overflow_to_sample_mapping')
+  
   return encoding
 
 # we need to define custom features for `set_format` (used later on) to work properly
@@ -239,7 +247,7 @@ training_args = TrainingArguments(
                   eval_steps=1000,
                   load_best_model_at_end=True,
                   metric_for_best_model="f1",
-                  output_dir="/mnt/data/models/layoutlmv3-large-fullyannotated",
+                  output_dir="/mnt/data/models/layoutlmv3-base-stride",
                   # resume_from_checkpoint="/mnt/data/models/layoutlmv3-large-finetuned-small-100/checkpoint-750",
                   fp16=True,
                 )
